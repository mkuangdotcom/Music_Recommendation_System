{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9hC/klUZeDXSCN5wNxXIb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkuangdotcom/Music_Recommendation_System/blob/main/User_Centric_Approach_to__Music_Recommendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "Music streaming platforms need to recommend relevant songs to users from millions of tracks.\n",
        "This project implements and compares three recommendation approaches:\n",
        "\n",
        "1. Baseline: Popularity-based recommendations (recommend top songs to everyone)\n",
        "2. ALS (Alternating Least Squares): Advanced collaborative filtering\n",
        "3. Factorization Machines: Machine learning with user features"
      ],
      "metadata": {
        "id": "BzsWzoEVk2ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we use the Last.fm 360K dataset, scaled to 10,000 users and 5,000 artists for computational efficiency.\n",
        "\n",
        "Dataset: http://ocelma.net/MusicRecommendationDataset/lastfm-360K.html (depreated)\n",
        "\n",
        "Download link: https://zenodo.org/record/6090214/files/lastfm-dataset-360K.tar.gz"
      ],
      "metadata": {
        "id": "LRooI8x6k-Vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "SiM01EczY8h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o lastfm-dataset-360K.tar.gz https://zenodo.org/records/6090214/files/lastfm-dataset-360K.tar.gz\n",
        "\n",
        "# Extract\n",
        "!tar -xzf lastfm-dataset-360K.tar.gz\n",
        "\n",
        "# Remove tar file\n",
        "!rm lastfm-dataset-360K.tar.gz\n",
        "\n",
        "data_path = 'lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv'"
      ],
      "metadata": {
        "id": "RmYBFiHyY8Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(data_path, sep='\\t', header=None,\n",
        "                 names=['user_id', 'artist_id', 'artist_name', 'play_count'])\n",
        "\n",
        "print(f\"Total interactions: {len(df):,}\")\n",
        "print(f\"Unique users: {df['user_id'].nunique():,}\")\n",
        "print(f\"Unique artists: {df['artist_id'].nunique():,}\")\n",
        "print(f\"Play count range: {df['play_count'].min()} - {df['play_count'].max()}\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xx8CIh1Labc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize and Scale the Data"
      ],
      "metadata": {
        "id": "B_df2SzYgUjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizations of user play counts, artist popularity, and user activity distributions."
      ],
      "metadata": {
        "id": "oxfmNn6jgnkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ejtLgHXbxTYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User activity analysis\n",
        "user_activity = df.groupby('user_id').agg({\n",
        "    'artist_id': 'count',      # number of different artists\n",
        "    'play_count': 'sum'        # total plays\n",
        "}).rename(columns={'artist_id': 'num_artists', 'play_count': 'total_plays'})\n",
        "\n",
        "print(\"User Activity Stats:\")\n",
        "print(f\"Average artists per user: {user_activity['num_artists'].mean():.1f}\")\n",
        "print(f\"Median artists per user: {user_activity['num_artists'].median()}\")\n",
        "print(f\"Most active user: {user_activity['num_artists'].max()} artists\")\n",
        "print(f\"Least active user: {user_activity['num_artists'].min()} artists\")\n",
        "\n",
        "# Artist popularity analysis\n",
        "artist_popularity = df.groupby('artist_id').agg({\n",
        "    'user_id': 'count',        # number of different users\n",
        "    'play_count': 'sum'        # total plays\n",
        "}).rename(columns={'user_id': 'num_listeners', 'play_count': 'total_plays'})\n",
        "\n",
        "print(\"\\nArtist Popularity Stats:\")\n",
        "print(f\"Average listeners per artist: {artist_popularity['num_listeners'].mean():.1f}\")\n",
        "print(f\"Median listeners per artist: {artist_popularity['num_listeners'].median()}\")\n",
        "print(f\"Most popular artist: {artist_popularity['num_listeners'].max()} listeners\")\n",
        "print(f\"Least popular artist: {artist_popularity['num_listeners'].min()} listeners\")"
      ],
      "metadata": {
        "id": "RO5ICXd6D1cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate user activity (number of unique artists per user)\n",
        "user_activity = df.groupby('user_id')['artist_id'].nunique().reset_index(name='num_artists')\n",
        "\n",
        "# Calculate artist popularity (number of unique listeners per artist)\n",
        "artist_popularity = df.groupby('artist_id')['user_id'].nunique().reset_index(name='num_listeners')\n",
        "\n",
        "# Visualize play count distribution\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.histplot(df['play_count'], bins=50, kde=False, color='skyblue')\n",
        "plt.title('Distribution of Play Counts')\n",
        "plt.xlabel('Play Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "# Visualize user activity distribution\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.histplot(user_activity['num_artists'], bins=50, kde=False, color='lightgreen')\n",
        "plt.title('Distribution of Number of Artists per User')\n",
        "plt.xlabel('Number of Artists')\n",
        "plt.ylabel('Number of Users')\n",
        "plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "# Visualize artist popularity distribution\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.histplot(artist_popularity['num_listeners'], bins=50, kde=False, color='salmon')\n",
        "plt.title('Distribution of Number of Listeners per Artist')\n",
        "plt.xlabel('Number of Listeners')\n",
        "plt.ylabel('Number of Artists')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JwAVebbPeJcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter and Scale"
      ],
      "metadata": {
        "id": "C7G0Cmxy-xR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter users with at least 5 unique artists\n",
        "user_counts = df.groupby('user_id').size()\n",
        "active_users = user_counts[user_counts >= 5].index\n",
        "df_filtered = df[df['user_id'].isin(active_users)]\n",
        "\n",
        "# Filter artists with at least 5 unique listeners\n",
        "artist_counts = df_filtered.groupby('artist_id').size()\n",
        "popular_artists = artist_counts[artist_counts >= 5].index\n",
        "df_filtered = df_filtered[df_filtered['artist_id'].isin(popular_artists)]\n",
        "\n",
        "# Scale down to the top 20,000 users\n",
        "top_users = df_filtered['user_id'].value_counts().head(20000).index\n",
        "df_scaled = df_filtered[df_filtered['user_id'].isin(top_users)]\n",
        "\n",
        "\n",
        "print(f\"Final scaled data: {len(df_scaled):,} interactions\")\n",
        "print(f\"Users: {df_scaled['user_id'].nunique():,}\")\n",
        "print(f\"Artists: {df_scaled['artist_id'].nunique():,}\")"
      ],
      "metadata": {
        "id": "UyH441HVgaNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "IDENmJFboIIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Create user and artist mappings\n",
        "user_mapping = {user: idx for idx, user in enumerate(df_scaled['user_id'].unique())}\n",
        "artist_mapping = {artist: idx for idx, artist in enumerate(df_scaled['artist_id'].unique())}\n",
        "\n",
        "# Map IDs to indices\n",
        "user_mapping = {user: idx for idx, user in enumerate(df_scaled['user_id'].unique())}\n",
        "artist_mapping = {artist: idx for idx, artist in enumerate(df_scaled['artist_id'].unique())}\n",
        "\n",
        "df_scaled['user_idx'] = df_scaled['user_id'].map(user_mapping)\n",
        "df_scaled['artist_idx'] = df_scaled['artist_id'].map(artist_mapping)\n",
        "\n",
        "# Create sparse matrix\n",
        "rows = df_scaled['user_idx'].values\n",
        "cols = df_scaled['artist_idx'].values\n",
        "data = df_scaled['play_count'].values\n",
        "sparse_matrix = csr_matrix((data, (rows, cols)),\n",
        "                           shape=(len(user_mapping), len(artist_mapping)))\n",
        "\n",
        "# Sparse Matrix Statistics\n",
        "print(f\"\\nSparse Matrix Statistics:\")\n",
        "print(f\"Shape: {sparse_matrix.shape}\")\n",
        "print(f\"Total possible entries: {sparse_matrix.shape[0] * sparse_matrix.shape[1]:,}\")\n",
        "print(f\"Non-zero entries: {sparse_matrix.nnz:,}\")\n",
        "sparsity_percent = (1 - sparse_matrix.nnz / (sparse_matrix.shape[0] * sparse_matrix.shape[1])) * 100\n",
        "print(f\"Sparsity: {sparsity_percent:.2f}%\")\n",
        "print(f\"Density: {100 - sparsity_percent:.2f}%\")"
      ],
      "metadata": {
        "id": "pPXIuqCYhLVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split"
      ],
      "metadata": {
        "id": "ptjmH6BQn93h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Split into train and test sets\n",
        "train_matrix = sparse_matrix.copy()\n",
        "test_interactions = []\n",
        "\n",
        "test_ratio = 0.2 # 20% for testing\n",
        "min_interactions = 5  # only consider users with at least 5 interactions\n",
        "\n",
        "for user_idx in range(sparse_matrix.shape[0]):\n",
        "    user_interactions = sparse_matrix.getrow(user_idx)\n",
        "    nonzero_items = user_interactions.nonzero()[1]\n",
        "\n",
        "    if len(nonzero_items) >= min_interactions:\n",
        "        n_test = max(1, int(len(nonzero_items) * test_ratio))\n",
        "        test_items = np.random.choice(nonzero_items, n_test, replace=False)\n",
        "\n",
        "        for item_idx in test_items:\n",
        "            test_interactions.append({\n",
        "                'user_idx': user_idx,\n",
        "                'item_idx': item_idx,\n",
        "                'rating': sparse_matrix[user_idx, item_idx]\n",
        "            })\n",
        "            train_matrix[user_idx, item_idx] = 0\n",
        "\n",
        "train_matrix.eliminate_zeros()\n",
        "\n",
        "print(f\"\\nTrain Matrix Statistics:\")\n",
        "print(f\"Shape: {train_matrix.shape}\")\n",
        "print(f\"Total possible entries: {train_matrix.shape[0] * train_matrix.shape[1]:,}\")\n",
        "print(f\"Non-zero entries: {train_matrix.nnz:,}\")\n",
        "train_sparsity = (1 - train_matrix.nnz / (train_matrix.shape[0] * train_matrix.shape[1])) * 100\n",
        "print(f\"Train set sparsity: {train_sparsity:.2f}%\")"
      ],
      "metadata": {
        "id": "bmxNqSLdoA5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for data leakage\n",
        "assert train_matrix.nnz + len(test_interactions) == sparse_matrix.nnz, \"Data leakage detected\"\n",
        "\n",
        "# Check sparsity\n",
        "train_sparsity = (1 - train_matrix.nnz / (train_matrix.shape[0] * train_matrix.shape[1])) * 100\n",
        "print(f\"Train set sparsity: {train_sparsity:.2f}%\")\n",
        "\n",
        "# Check for cold-start users\n",
        "train_user_counts = np.array(train_matrix.sum(axis=1)).flatten()\n",
        "cold_start_users = np.sum(train_user_counts == 0)\n",
        "print(f\"Cold-start users: {cold_start_users}\")"
      ],
      "metadata": {
        "id": "TRV99m6u_Jqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Implementation and Training\n",
        "\n",
        "We'll implement two advanced recommendation approaches:\n",
        "1. **Baseline**: Popularity-based recommendations for comparison\n",
        "2. **ALS (Alternating Least Squares)**: Matrix factorization optimized for implicit feedback"
      ],
      "metadata": {
        "id": "ajWu9pKCE0ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Model: Popularity-Based Recommendations\n",
        "\n",
        "First, let's establish our baseline by identifying the most popular artists based on total play counts across all training users."
      ],
      "metadata": {
        "id": "zh0_cr1kG_jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate artist popularity from training data\n",
        "artist_popularity = np.array(train_matrix.sum(axis=0)).flatten()\n",
        "\n",
        "# Get top artists for baseline recommendations\n",
        "n_recommendations = 10\n",
        "top_artists_baseline = np.argsort(artist_popularity)[::-1][:n_recommendations]\n",
        "\n",
        "print(\"Baseline Model - Most Popular Artists:\")\n",
        "for i, artist_idx in enumerate(top_artists_baseline):\n",
        "    plays = artist_popularity[artist_idx]\n",
        "    print(f\"  {i+1}. Artist {artist_idx}: {plays:,.0f} total plays\")"
      ],
      "metadata": {
        "id": "IoAcP5VqG_FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ALS Model: Collaborative Filtering\n",
        "\n",
        "ALS (Alternating Least Squares) is a matrix factorization technique that learns latent user and item factors by alternately optimizing user and item representations. It's particularly well-suited for implicit feedback data like play counts.\n",
        "\n",
        "Key advantages:\n",
        "- Handles sparse matrices efficiently\n",
        "- Optimized for implicit feedback (play counts vs explicit ratings)\n",
        "- Scalable to large datasets"
      ],
      "metadata": {
        "id": "CGaKN7I5HVsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from implicit.als import AlternatingLeastSquares\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate(model, test_sample, k=10):\n",
        "    \"\"\"\n",
        "      Quick evaluation on sample of test data for hyperparameter search.\n",
        "\n",
        "      Args:\n",
        "          model: Trained ALS model\n",
        "          test_sample (list): Test interactions\n",
        "          k (int): Number of recommendations\n",
        "\n",
        "      Returns:\n",
        "          float: Average precision@k across sampled users\n",
        "    \"\"\"\n",
        "    precisions = []\n",
        "\n",
        "    # Sample 1000 users for fast evaluation\n",
        "    user_test_items = {}\n",
        "    for interaction in test_sample:\n",
        "        user_idx = interaction['user_idx']\n",
        "        if user_idx not in user_test_items:\n",
        "            user_test_items[user_idx] = []\n",
        "        user_test_items[user_idx].append(interaction['item_idx'])\n",
        "        if len(user_test_items) >= 1000:\n",
        "            break\n",
        "\n",
        "    for user_idx, true_items in user_test_items.items():\n",
        "        try:\n",
        "            user_items = train_matrix[user_idx].tocsr()\n",
        "            recs, _ = model.recommend(userid=user_idx, user_items=user_items, N=k)\n",
        "            hits = len(set(recs) & set(true_items))\n",
        "            precisions.append(hits / k)\n",
        "        except:\n",
        "            precisions.append(0)\n",
        "\n",
        "    return np.mean(precisions)\n",
        "\n",
        "# Parameter search space\n",
        "param_space = {\n",
        "    'factors': [30, 50, 70, 100],\n",
        "    'regularization': [0.001, 0.01, 0.05, 0.1],\n",
        "    'iterations': [10, 15, 20],\n",
        "    'alpha': [0.5, 1.0, 2.0, 5.0]\n",
        "}\n",
        "\n",
        "# Random search configuration\n",
        "n_trials = 12\n",
        "results = []\n",
        "\n",
        "print(f\"Random Hyperparameter Search: {n_trials} trials\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for trial in tqdm(range(n_trials), desc=\"Searching hyperparameters\", ncols=80):\n",
        "    # Sample random parameters\n",
        "    params = {\n",
        "        'factors': np.random.choice(param_space['factors']),\n",
        "        'regularization': np.random.choice(param_space['regularization']),\n",
        "        'iterations': np.random.choice(param_space['iterations']),\n",
        "        'alpha': np.random.choice(param_space['alpha']),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    # Train and evaluate\n",
        "    model = AlternatingLeastSquares(**params)\n",
        "    model.fit(train_matrix.tocsr(), show_progress=False)\n",
        "    precision = evaluate(model, test_interactions, k=10)\n",
        "\n",
        "    tqdm.write(f\"Trial {trial+1:2d}: P@10={precision:.4f} | \"\n",
        "               f\"f={params['factors']:3d} r={params['regularization']:.3f} \"\n",
        "               f\"i={params['iterations']:2d} a={params['alpha']:.1f}\")\n",
        "\n",
        "    results.append({\n",
        "        **params,\n",
        "        'precision': precision,\n",
        "    })\n",
        "\n",
        "# Results summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "results_df = pd.DataFrame(results).sort_values('precision', ascending=False)\n",
        "print(\"Top 3 Configurations:\")\n",
        "print(results_df[['factors', 'regularization', 'iterations', 'alpha', 'precision']].head(3).to_string(index=False))\n",
        "\n",
        "# Best parameters\n",
        "best = results_df.iloc[0]\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Best Parameters:\")\n",
        "print(f\"  factors={int(best['factors'])}, regularization={best['regularization']}, \"\n",
        "      f\"iterations={int(best['iterations'])}, alpha={best['alpha']}\")\n",
        "print(f\"  Validation Precision@10: {best['precision']:.4f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Train final model with best parameters\n",
        "als_model = AlternatingLeastSquares(\n",
        "    factors=int(best['factors']),\n",
        "    regularization=best['regularization'],\n",
        "    iterations=int(best['iterations']),\n",
        "    alpha=best['alpha'],\n",
        "    random_state=42\n",
        ")\n",
        "als_model.fit(train_matrix.tocsr(), show_progress=True)\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "id": "G0SCrrPvQbR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation Generation Functions\n",
        "\n",
        "We'll implement functions to generate recommendations from both our baseline and ALS models, then evaluate their performance using standard recommendation metrics."
      ],
      "metadata": {
        "id": "gFFYKcsUHtEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_baseline_recommendations(k=10):\n",
        "    \"\"\"Return top K popular artists.\"\"\"\n",
        "    return top_artists_baseline[:k]\n",
        "\n",
        "def get_als_recommendations(user_idx, k=10):\n",
        "    \"\"\"\n",
        "    Get personalized ALS recommendations for a user.\n",
        "\n",
        "    Args:\n",
        "        user_idx: user index (0 to n_users-1)\n",
        "        k: number of recommendations\n",
        "\n",
        "    Returns:\n",
        "        artist_indices: array of recommended artist IDs\n",
        "        scores: prediction scores\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get user's listening history (for filtering)\n",
        "        user_items = train_matrix[user_idx].tocsr()\n",
        "\n",
        "        recs, scores = als_model.recommend(\n",
        "            userid=user_idx,\n",
        "            user_items=user_items,\n",
        "            N=k,\n",
        "            filter_already_liked_items=True\n",
        "        )\n",
        "        return recs, scores\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting recommendations for user {user_idx}: {e}\")\n",
        "        # Fallback to baseline\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "# Test the functions\n",
        "print(\"Testing recommendation functions...\")\n",
        "test_user = 0\n",
        "baseline_recs = get_baseline_recommendations(5)\n",
        "als_recs, als_scores = get_als_recommendations(test_user, 5)\n",
        "\n",
        "print(f\"Baseline recommendations: {baseline_recs}\")\n",
        "print(f\"ALS recommendations for user {test_user}: {als_recs}\")\n",
        "print(f\"ALS scores: {als_scores}\")"
      ],
      "metadata": {
        "id": "3pxojwGZHq7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation and Comparison\n",
        "\n",
        "Now we'll evaluate both models on our test set and compare their performance across multiple metrics."
      ],
      "metadata": {
        "id": "gCCRFRtcH2I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_recommendations(model_name, get_recs_func, test_interactions, k=10):\n",
        "    \"\"\"\n",
        "    Evaluate recommendation quality using multiple metrics.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model being evaluated\n",
        "        get_recs_func (function): Function that generates recommendations\n",
        "                                   For baseline: takes only k\n",
        "                                   For other models: takes (user_idx, k)\n",
        "        test_interactions (list): List of test interaction dictionaries with keys:\n",
        "                                  'user_idx', 'item_idx', 'rating'\n",
        "        k (int): Number of recommendations to evaluate (default: 10)\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing evaluation metrics:\n",
        "              - precision: Average precision@k across all users\n",
        "              - recall: Average recall@k across all users\n",
        "              - ndcg: Average NDCG@k across all users\n",
        "              - coverage: Fraction of items recommended at least once\n",
        "              - name: Model name string\n",
        "    \"\"\"\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "    # Group test items by user\n",
        "    user_test_items = {}\n",
        "    for interaction in test_interactions:\n",
        "        user_idx = interaction['user_idx']\n",
        "        artist_idx = interaction['item_idx']\n",
        "        if user_idx not in user_test_items:\n",
        "            user_test_items[user_idx] = []\n",
        "        user_test_items[user_idx].append(artist_idx)\n",
        "\n",
        "    print(f\"  Evaluating on {len(user_test_items)} users\")\n",
        "\n",
        "    # Initialize metric lists\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    ndcgs = []\n",
        "    all_recommended = set()\n",
        "\n",
        "    for user_idx, true_items in user_test_items.items():\n",
        "        # Get recommendations based on model type\n",
        "        if model_name == \"Baseline\":\n",
        "            recs = get_recs_func(k)\n",
        "        else:\n",
        "            recs, _ = get_recs_func(user_idx, k)\n",
        "\n",
        "        # Ensure recommendations are valid indices\n",
        "        recs = np.array(recs)\n",
        "        valid_recs = recs[recs < train_matrix.shape[1]]\n",
        "\n",
        "        # Calculate hits\n",
        "        rec_set = set(valid_recs)\n",
        "        true_set = set(true_items)\n",
        "        hits = len(rec_set & true_set)\n",
        "\n",
        "        # Precision@k: fraction of recommendations that are relevant\n",
        "        precision = hits / k if k > 0 else 0\n",
        "        precisions.append(precision)\n",
        "\n",
        "        # Recall@k: fraction of relevant items that are recommended\n",
        "        recall = hits / len(true_set) if len(true_set) > 0 else 0\n",
        "        recalls.append(recall)\n",
        "\n",
        "        # NDCG@k: ranking quality metric (relevant items at top positions score higher)\n",
        "        dcg = 0.0\n",
        "        for i, item in enumerate(valid_recs[:k]):\n",
        "            if item in true_set:\n",
        "                dcg += 1.0 / np.log2(i + 2)\n",
        "\n",
        "        idcg = 0.0\n",
        "        for i in range(min(len(true_set), k)):\n",
        "            idcg += 1.0 / np.log2(i + 2)\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        ndcgs.append(ndcg)\n",
        "\n",
        "        # Track all recommended items for coverage\n",
        "        all_recommended.update(valid_recs)\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_precision = np.mean(precisions)\n",
        "    avg_recall = np.mean(recalls)\n",
        "    avg_ndcg = np.mean(ndcgs)\n",
        "    coverage = len(all_recommended) / train_matrix.shape[1]\n",
        "\n",
        "    print(f\"  Precision@{k}: {avg_precision:.4f}\")\n",
        "    print(f\"  Recall@{k}: {avg_recall:.4f}\")\n",
        "    print(f\"  NDCG@{k}: {avg_ndcg:.4f}\")\n",
        "    print(f\"  Coverage: {coverage:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'precision': avg_precision,\n",
        "        'recall': avg_recall,\n",
        "        'ndcg': avg_ndcg,\n",
        "        'coverage': coverage,\n",
        "        'name': model_name\n",
        "    }"
      ],
      "metadata": {
        "id": "IJZazULLH4yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline\n",
        "baseline_results = evaluate_recommendations(\n",
        "    \"Baseline\",\n",
        "    get_baseline_recommendations,\n",
        "    test_interactions,\n",
        "    k=10\n",
        ")\n",
        "\n",
        "# Evaluate ALS\n",
        "als_results = evaluate_recommendations(\n",
        "    \"ALS\",\n",
        "    get_als_recommendations,\n",
        "    test_interactions,\n",
        "    k=10\n",
        ")\n",
        "\n",
        "# Compare results\n",
        "print(f\"\\n{'Metric':<15} {'Baseline':<12} {'ALS':<12} {'Improvement'}\")\n",
        "print(\"-\"*60)\n",
        "for metric in ['precision', 'recall', 'ndcg', 'coverage']:\n",
        "    base = baseline_results[metric]\n",
        "    als = als_results[metric]\n",
        "    improvement = ((als - base) / base * 100) if base > 0 else 0\n",
        "    print(f\"{metric.capitalize():<15} {base:<12.4f} {als:<12.4f} {improvement:>+7.1f}%\")"
      ],
      "metadata": {
        "id": "OZrYjl_2Wv8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Performance comparison\n",
        "metrics = ['Precision@10', 'Recall@10', 'NDCG@10', 'Coverage']\n",
        "baseline_vals = [baseline_results['precision'], baseline_results['recall'], baseline_results['ndcg'], baseline_results['coverage']]\n",
        "als_vals = [als_results['precision'], als_results['recall'], als_results['ndcg'], als_results['coverage']]\n",
        "\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.8, color='skyblue')\n",
        "axes[0].bar(x + width/2, als_vals, width, label='ALS Model', alpha=0.8, color='lightcoral')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Model Performance Comparison')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(metrics)\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Improvement percentages\n",
        "improvements = []\n",
        "for base, als in zip(baseline_vals, als_vals):\n",
        "    imp = ((als - base) / base * 100) if base > 0 else 0\n",
        "    improvements.append(imp)\n",
        "\n",
        "colors = ['green' if x > 0 else 'red' for x in improvements]\n",
        "bars = axes[1].bar(metrics, improvements, color=colors, alpha=0.7)\n",
        "axes[1].set_ylabel('Improvement (%)')\n",
        "axes[1].set_title('ALS vs Baseline Improvement')\n",
        "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars, improvements):\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height + (2 if height > 0 else -5),\n",
        "                f'{val:.1f}%', ha='center', va='bottom' if height > 0 else 'top')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P66FZSrfH83b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Recommendations Analysis\n",
        "\n",
        "Let's examine actual recommendations for a sample user to understand the difference between baseline and collaborative filtering approaches."
      ],
      "metadata": {
        "id": "4inHpfJ0H_k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_user = 0\n",
        "\n",
        "# User's profile\n",
        "user_artists = train_matrix[sample_user].nonzero()[1]\n",
        "total_plays = train_matrix[sample_user].sum()\n",
        "\n",
        "print(f\"Sample User {sample_user} Profile:\")\n",
        "print(f\"  Artists listened to: {len(user_artists)}\")\n",
        "print(f\"  Total plays: {total_plays}\")\n",
        "\n",
        "# Get recommendations\n",
        "baseline_recs = get_baseline_recommendations(5)\n",
        "als_recs, als_scores = get_als_recommendations(sample_user, 5)\n",
        "\n",
        "print(f\"\\nBaseline Recommendations (Same for Everyone):\")\n",
        "for i, artist_idx in enumerate(baseline_recs):\n",
        "    plays = int(artist_popularity[artist_idx])\n",
        "    print(f\"  {i+1}. Artist {artist_idx} ({plays:,} total plays)\")\n",
        "\n",
        "print(f\"\\nALS Recommendations (Personalized for User {sample_user}):\")\n",
        "for i, (artist_idx, score) in enumerate(zip(als_recs, als_scores)):\n",
        "    print(f\"  {i+1}. Artist {artist_idx} (score: {score:.3f})\")\n",
        "\n",
        "# Check against test set\n",
        "user_test_items = [item['item_idx'] for item in test_interactions if item['user_idx'] == sample_user]\n",
        "if user_test_items:\n",
        "    baseline_hits = len(set(baseline_recs) & set(user_test_items))\n",
        "    als_hits = len(set(als_recs) & set(user_test_items))\n",
        "    print(f\"\\nActual Relevance (Test Set Hits):\")\n",
        "    print(f\"  Baseline: {baseline_hits}/5\")\n",
        "    print(f\"  ALS: {als_hits}/5\")"
      ],
      "metadata": {
        "id": "VpPcXcoWIBQo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}